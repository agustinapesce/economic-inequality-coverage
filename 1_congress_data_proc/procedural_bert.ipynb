{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ran in David's team server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Automatic procedural cliff as detailed in Jurafsky's 140 years paper but with BERT cliff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crec_new = pd.read_csv(\"crec2023_2024.csv\", engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = crec_new[\"speech\"].to_list()\n",
    "speeches = list(map(str, speeches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Exclude speeches shorter than 3 words or 16 characters (20 cause punctuation)\n",
    "def filter_short_speeches(speeches):\n",
    "    return [s for s in speeches if (len(s.split()) >= 3 or len(s) >= 20)] \n",
    "\n",
    "# Step 2: Identify procedural speeches\n",
    "# 5 repeats instead of 20 cause smaller dataset, 210 instead of 200 cause preprocessing does not include punctuation removal\n",
    "def identify_procedural_speeches(speeches, min_repeats=5, max_length=210): \n",
    "    counter = Counter([s for s in speeches if len(s) <= max_length]) #every speech is only once and counted\n",
    "    procedural = [speech for speech, count in counter.items() if count >= min_repeats]\n",
    "    return procedural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° of procedural speeches = 910\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and filter\n",
    "speeches = filter_short_speeches(speeches)\n",
    "\n",
    "# Identify procedural speeches\n",
    "procedural_speeches = identify_procedural_speeches(speeches)\n",
    "print(f\"N° of procedural speeches = {len(procedural_speeches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-procedural speeches\n",
    "non_procedural_length=1000\n",
    "non_procedural = [s for s in speeches if len(s) > non_procedural_length and len(s.split()) > 20]\n",
    "chunks = []\n",
    "for speech in non_procedural:\n",
    "    chunks.extend([speech[i:i+200] for i in range(0, len(speech), 200)])\n",
    "\n",
    "negative_cases = np.random.choice(chunks, size=int(0.05 * len(chunks)), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_randomly(lst, seed, ratio = 0.75):\n",
    "    random.seed(seed)  # Set the seed for reproducibility\n",
    "    random.shuffle(lst)  # Shuffle the list randomly\n",
    "    split_point = int(len(lst) * ratio)\n",
    "    return lst[:split_point], lst[split_point:]\n",
    "\n",
    "# Perform the splits\n",
    "seed_value = 42\n",
    "procedural_speeches_train, procedural_speeches_test = split_list_randomly(procedural_speeches, seed=seed_value)\n",
    "negative_cases_train, negative_cases_test = split_list_randomly(negative_cases, seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare training data\n",
    "def prepare_training_data(negative_cases_train, procedural_speeches_train):\n",
    "    # Positive examples: 100% of procedural speeches\n",
    "    procedural_training = np.random.choice(procedural_speeches_train, \n",
    "                                           size=int(1 * len(procedural_speeches_train)), \n",
    "                                           replace=False)\n",
    "\n",
    "    # Combine training data\n",
    "    X_train = list(procedural_training) + list(negative_cases_train)\n",
    "    y_train = [1] * len(procedural_training) + [0] * len(negative_cases_train)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X_train, y_train = prepare_training_data(negative_cases_train, procedural_speeches_train)\n",
    "\n",
    "# Prepare test data\n",
    "X_test = list(procedural_speeches_test) + list(negative_cases_test)\n",
    "y_test = [1] * len(procedural_speeches_test) + [0] * len(negative_cases_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for BERT\n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Step 5: Train BERT classifier\n",
    "def train_bert_classifier(X_train, y_train, max_length=128, epochs=3, batch_size=16):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "    train_dataset = SpeechDataset(X_train, y_train, tokenizer, max_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    #criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = train_bert_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate BERT classifier\n",
    "def evaluate_bert_classifier(tokenizer, model, X_test, y_test, max_length=128, batch_size=16):\n",
    "    test_dataset = SpeechDataset(X_test, y_test, tokenizer, max_length)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9985\n",
      "F1 Score: 0.9803\n",
      "Precision: 0.9782\n",
      "Recall: 0.9825\n"
     ]
    }
   ],
   "source": [
    "evaluate_bert_classifier(tokenizer, model, X_test, y_test)\n",
    "\n",
    "#Accuracy: 0.9980\n",
    "#F1 Score: 0.9740\n",
    "#Precision: 0.9574\n",
    "#Recall: 0.9912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_procedural_speeches(df, column_name, tokenizer, model, max_length=128, batch_size=16):\n",
    "    \"\"\"\n",
    "    Classify speeches in a DataFrame column as procedural or not, skipping BERT for specific cases, \n",
    "    and add a 'procedural_flag' column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing speeches.\n",
    "        column_name (str): Column name where speeches are stored.\n",
    "        tokenizer (BertTokenizer): Tokenizer for BERT model.\n",
    "        model (BertForSequenceClassification): Trained BERT model.\n",
    "        max_length (int): Maximum sequence length for BERT input.\n",
    "        batch_size (int): Batch size for inference.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'procedural_flag' column.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Convert speeches to strings and handle missing values\n",
    "    df[column_name] = df[column_name].astype(str).fillna(\"\")\n",
    "\n",
    "    # Step 1: Flag very short speeches as procedural\n",
    "    def is_very_short(speech):\n",
    "        return len(speech.split()) <= 3 or len(speech) <= 20\n",
    "\n",
    "    df['procedural_flag'] = df[column_name].apply(lambda x: 1 if is_very_short(x) else 0)\n",
    "\n",
    "    # Step 2: Filter out speeches already flagged as procedural\n",
    "    non_very_short_speeches = df[df['procedural_flag'] == 0][column_name].tolist()\n",
    "    short_speeches = [speech for speech in non_very_short_speeches if len(speech) <= 420]\n",
    "\n",
    "    # Step 3: Prepare data for BERT\n",
    "    dataset = SpeechDataset(short_speeches, [0] * len(short_speeches), tokenizer, max_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    # Step 4: Classify remaining speeches with BERT\n",
    "    procedural_flags = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            procedural_flags.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Step 5: Map BERT classifications back to speeches\n",
    "    flag_mapping = {speech: flag for speech, flag in zip(short_speeches, procedural_flags)}\n",
    "\n",
    "    # Step 6: Update the procedural_flag column for speeches classified with BERT\n",
    "    def update_flag(speech, existing_flag):\n",
    "        if existing_flag == 1:\n",
    "            return 1  # Already flagged as procedural by the rule\n",
    "        return flag_mapping.get(speech, 0)  # Use BERT classification otherwise\n",
    "\n",
    "    df['procedural_flag'] = df.apply(lambda row: update_flag(row[column_name], row['procedural_flag']), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "crec_procflag = flag_procedural_speeches(crec_new, \"speech\", tokenizer, model, max_length=128, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All crec: 98187\n",
      "Flagged crec: 54079\n",
      "%flagged: 55.08\n"
     ]
    }
   ],
   "source": [
    "all_speeches = len(crec_procflag)\n",
    "print(\"All crec:\", all_speeches)\n",
    "flagged_proc = len(crec_procflag[crec_procflag[\"procedural_flag\"]==1])\n",
    "print(\"Flagged crec:\", flagged_proc)\n",
    "\n",
    "print(\"%flagged:\", round(flagged_proc*100/all_speeches,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "crec_procflag.to_csv(\"crec_procflag.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./trained_bert/tokenizer_config.json',\n",
       " './trained_bert/special_tokens_map.json',\n",
       " './trained_bert/vocab.txt',\n",
       " './trained_bert/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./trained_bert\")\n",
    "tokenizer.save_pretrained(\"./trained_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crec_see = pd.read_csv(\"crec_procflag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crec_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['speech_id', 'speech', 'chamber', 'is_extension', 'date', 'speaker',\n",
       "       'speaker_bioguide', 'vol', 'num', 'congress_num', 'pages', 'doc_title',\n",
       "       'title', 'procedural_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crec_see.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of speeches meeting criteria with procedural_flag == 1: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN values in the speech column\n",
    "crec_see = crec_see.dropna(subset=['speech'])\n",
    "\n",
    "# Filter speeches based on the length criteria\n",
    "filtered_speeches = crec_see[(crec_see['speech'].str.split().apply(len) <= 3) | (crec_see['speech'].str.len() <= 20)]\n",
    "\n",
    "# Calculate the proportion where procedural_flag == 1\n",
    "proportion_procedural = (filtered_speeches[\"procedural_flag\"] == 1).mean()\n",
    "\n",
    "print(\"Proportion of speeches meeting criteria with procedural_flag == 1:\", proportion_procedural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_flagged 5616\n",
      "flagged 54079\n"
     ]
    }
   ],
   "source": [
    "non_flagged = len(crec_procflag[(crec_procflag[\"procedural_flag\"] == 0) & (crec_procflag[\"speech\"].str.len() <= 420)][\"speech\"])\n",
    "print(\"non_flagged\", non_flagged)\n",
    "\n",
    "flagged = len(crec_procflag[(crec_procflag[\"procedural_flag\"] == 1) & (crec_procflag[\"speech\"].str.len() <= 420)][\"speech\"])\n",
    "print(\"flagged\", flagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The objection is heard.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Mr. Speaker, I continue to reserve the balance of my time.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "The gentleman from Pennsylvania is recognized for 1 hour.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Under the previous order, the question is, Shall the joint resolution (S.J. Res. 11) pass, the objections of the President to the contrary notwithstanding? The yeas and nays are required under the Constitution. The clerk will call the roll.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Is there a sufficient second? There appears to be a sufficient second. The clerk will call the roll.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Pursuant to clause 8 of rule XX, the Chair will postpone further proceedings on motions to suspend the rules on which a recorded vote or the yeas and nays are ordered, or votes objected to under clause 6 of rule XX. The House will resume proceedings on postponed questions at a later time.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Pursuant to the rule, the gentleman from Ohio (Mr. Latta) and the gentleman from New Jersey (Mr. Pallone) each will control 20 minutes. The Chair recognizes the gentleman from Ohio. General Leave\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Mr. President, I ask unanimous consent that the Committee on the Judiciary be discharged from further consideration of S. Res. 895 and the Senate proceed to its immediate consideration.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Without objection, it is so ordered.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Without objection, it is so ordered. Defense Foreign Policy\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "It is now in order to consider amendment No. 54 printed in part B of House Report 118-242.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "The clerk will report the nomination. The bill clerk read the nomination of Kymberly Kathryn Evanson, of Washington, to be United States District Judge for the Western District of Washington. Thereupon, the Senate proceeded to consider the nomination.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Without objection, it is so ordered.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "I ask for the yeas and nays.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "I ask unanimous consent that the mandatory quorum calls for the cloture motions filed today, September 25, be waived.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Mr. President, I ask unanimous consent to complete my remarks prior to the scheduled rollcall votes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Pursuant to clause 8 of rule XX, further proceedings on this question are postponed.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Pursuant to House Resolution 847, the gentleman from South Carolina (Mr. Norman) and a Member opposed each will control 5 minutes. The Chair recognizes the gentleman from South Carolina.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Is there objection to the request of the gentleman from Arkansas?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Mr. Speaker, I yield 2 minutes to the distinguished gentleman from Missouri (Mr. Alford), who is my very good friend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select 20 random procedural speeches\n",
    "filtered_speeches = crec_procflag[(crec_procflag[\"procedural_flag\"] == 1) & (crec_procflag[\"speech\"].str.len() <= 420)][\"speech\"]\n",
    "\n",
    "random_speeches = random.sample(list(filtered_speeches), 20)\n",
    "\n",
    "# Display all the selected speeches completely\n",
    "for speech in random_speeches:\n",
    "    print()\n",
    "    print(speech)\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")  # Separator between speeches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
